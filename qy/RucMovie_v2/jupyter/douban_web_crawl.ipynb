{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f47c2114-a08a-46de-baa2-2b7b613d2bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "from time import sleep\n",
    "import re\n",
    "\n",
    "DIRDATA = 'data/豆瓣高分电影.xlsx'\n",
    "DOUBAN_MOVIES = pd.read_excel(DIRDATA, sheet_name='movie', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8cf2e1-ae24-49c9-8988-a6ed6ec90d10",
   "metadata": {},
   "source": [
    "# crawling movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72669ff0-253e-4e07-83ba-3e37e28a6744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"def douban_movie(movie_id):\n",
    "    res = None\n",
    "    url = f'https://movie.douban.com/subject/{movie_id}'\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36 Edg/119.0.0.0'}\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            html = response.text\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            json_str = soup.find('script', {'type': 'application/ld+json'}).text\n",
    "            res = json.loads(json_str)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"\\n### Error during the request: {e}\")\n",
    "    finally:\n",
    "        if res is None:\n",
    "            print(\"\\n not properly loaded!\")\n",
    "        return res\n",
    "    \n",
    "movies = {}    \n",
    "for nums, movie_id in enumerate(DOUBAN_MOVIES.index[:]):\n",
    "    print(nums, end='-')\n",
    "    res = douban_movie(movie_id)\n",
    "    if res is not None:\n",
    "        movies[movie_id] = res\n",
    "    sleep(3)\n",
    "file_path = f\"douban_json/movies.json\"\n",
    "with open(file_path, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(movies, json_file) \n",
    "movies = pd.DataFrame.from_dict(movies, orient ='index')\n",
    "movies.index.name= 'movie_id'\n",
    "movies['name'] = movies.index.map(DOUBAN_MOVIES['电影名'])\n",
    "movies['description'] = movies.index.map(DOUBAN_MOVIES['电影简介']).str.strip()\n",
    "file_path = f\"douban/movies.csv\"\n",
    "movies.to_csv(file_path)\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fbdf034-46d5-414d-9310-a9cb09730917",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = f\"douban/movies.csv\"\n",
    "movies = pd.read_csv(file_path, index_col=0)\n",
    "\n",
    "cols_str = ['director', 'author', 'actor', 'genre', 'aggregateRating']\n",
    "movies[cols_str] = movies[cols_str].map(eval)\n",
    "\n",
    "movies['name'] = movies.index.map(DOUBAN_MOVIES['电影名'])\n",
    "movies['country'] = movies.index.map(DOUBAN_MOVIES['制片地区'])\n",
    "movies['description'] = movies.index.map(DOUBAN_MOVIES['电影简介']).str.strip()\n",
    "\n",
    "file_path = f\"douban/movies.csv\"\n",
    "movies.to_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9cc280ae-f392-4161-adc3-65f7614da961",
   "metadata": {},
   "outputs": [],
   "source": [
    "relations = pd.DataFrame()\n",
    "for col in ['director', 'author', 'actor']:\n",
    "    for movie_id in movies.index:\n",
    "        df = pd.DataFrame(movies.loc[movie_id, col])\n",
    "        df['movie_id'] = movie_id\n",
    "        df['movie_role'] = col\n",
    "        relations = pd.concat([relations, df])    \n",
    "relations['person_id'] = relations.url.str.extract('(\\d+)').astype(np.int64)  \n",
    "relations[['person_id', 'movie_id', 'movie_role']].to_csv('douban/relations.csv', index=False)\n",
    "\n",
    "\n",
    "celebrities = relations[['person_id', 'name']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "celebrities[['name_cn', 'name_en']] = celebrities.name.str.strip().str.replace(' ', '|', 1).str.split('|', expand=True).fillna('')\n",
    "celebrities.to_csv('douban/celebrities.csv', index=False)\n",
    "person_ids = relations['person_id'].unique()\n",
    "pd.DataFrame(person_ids).to_csv('douban/person_ids.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f1b419d-aab8-4b0e-960c-6d1f3a00730f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"def douban_person(person_id):\n",
    "    person = None\n",
    "    url = f'https://movie.douban.com/celebrity/{person_id}'\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36 Edg/119.0.0.0'}\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            html = response.text\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            person = pd.DataFrame(\n",
    "                data= [li.text.strip().split('\\n') for li in soup.find_all('div', {'class': 'info'})[0].find_all('li')],\n",
    "                columns=['title', 'content']\n",
    "            )\n",
    "            person['title'] = person['title'].str.replace(' |:', '', regex=True)\n",
    "            person['content'] = person['content'].str.strip()\n",
    "            person = person.set_index('title')['content']\n",
    "            person = person.to_dict()\n",
    "            person['image'] = soup.find('div', {'class': \"nbg\"}).find('img').get('src')\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"\\n### Error during the request: {e}\")\n",
    "    finally:\n",
    "        if person is None:\n",
    "            print(\"not properly loaded!\")\n",
    "        return person\n",
    "    \n",
    "persons = {}\n",
    "for num, person_id in enumerate(person_ids[:]):\n",
    "    print(num, end='-')\n",
    "    person = douban_person(person_id)\n",
    "    if person is not None:\n",
    "        persons[person_id] = person\n",
    "    sleep(1)\n",
    "    \n",
    "persons_str = {str(key): value for key, value in persons.items()}\n",
    "file_path = f\"douban/persons.json\"\n",
    "with open(file_path, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(persons_str, json_file)\n",
    "    \n",
    "persons = pd.DataFrame.from_dict(persons, orient='index')\n",
    "persons.index.name = 'movie_id'\n",
    "persons.index =persons.index.astype(np.int64)\n",
    "file_path = f\"douban/persons.csv\"\n",
    "persons.to_csv(file_path)\n",
    "\"\"\"\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6476b4e3-1991-4fc6-9625-4123f04c1afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "persons = pd.read_csv('douban/persons.csv', index_col=0)\n",
    "persons = celebrities.set_index('person_id').join(persons)\n",
    "persons.to_csv('douban/celebrities.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b195f8cc-69fd-420e-986e-038b9db6f6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e60a67-2bbb-4f57-8e93-31f49a91fe24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
